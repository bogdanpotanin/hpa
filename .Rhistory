#Calculate latent and observable variables values
z_star <- 1 + X[, 1] + X[, 2] + epsilon
z <- as.numeric((z_star > 0))
#Store the results into dataframe
h <- as.data.frame(cbind(z,X))
names(h) <- c("z", "x1", "x2")
#Estimate model parameters
model <- hpaBinary(formula = z ~ x1 + x2, data=h, K = 3)
summary(model)
system.time(hpaBinary(formula = z ~ x1 + x2, data=h, K = 3))
system.time(hpaBinary(formula = z ~ x1 + x2, data=h, K = 3))
system.time(hpaBinary(formula = z ~ x1 + x2, data=h, K = 3))
roxygen2::roxygenize(".", roclets="rd")
help(hpaBinary)
roxygen2::roxygenize(".", roclets="rd")
help(hpaBinary)
## Estimate survival probability on Titanic
library("titanic")
#Prepare data set converting
#all variables to numeric vectors
h <- data.frame("male" = as.numeric(titanic_train$Sex == "male"))
h$class_1 <- as.numeric(titanic_train$Pclass == 1)
h$class_2 <- as.numeric(titanic_train$Pclass == 2)
h$class_3 <- as.numeric(titanic_train$Pclass == 3)
h$sibl <- titanic_train$SibSp
h$survived <- titanic_train$Survived
h$age <- titanic_train$Age
h$parch <- titanic_train$Parch
h$fare <- titanic_train$Fare
#Estimate model parameters
model_hpa_1 <- hpaBinary(survived ~class_1 + class_2 +
male + age + sibl + parch + fare,
K = 3, data = h)
#get summary
summary(model_hpa_1)
#Get predicted probabilities
pred_hpa_1 <- predict(model_hpa_1)
#Calculate number of correct predictions
hpa_1_correct_0 <- sum((pred_hpa_1 < 0.5) & (model_hpa_1$dataframe$survived == 0))
hpa_1_correct_1 <- sum((pred_hpa_1 >= 0.5) & (model_hpa_1$dataframe$survived == 1))
hpa_1_correct <- hpa_1_correct_1 + hpa_1_correct_0
#Plot random errors density approximation
plot(model_hpa_1)
##Estimate parameters on data simulated from student distribution
library("mvtnorm")
set.seed(123456)
#Simulate independent variables from normal distribution
n <- 1000
X <- rmvnorm(n=n, mean = c(0,0),
sigma = matrix(c(1,0.5,0.5,1), ncol=2))
#Simulate random errors
epsilon <- rt(n, 5) * (3 / sqrt(5))
#Calculate latent and observable variables values
z_star <- 1 + X[, 1] + X[, 2] + epsilon
z <- as.numeric((z_star > 0))
#Store the results into dataframe
h <- as.data.frame(cbind(z,X))
names(h) <- c("z", "x1", "x2")
#Estimate model parameters
model <- hpaBinary(formula = z ~ x1 + x2, data=h, K = 3)
summary(model)
#Get predicted probabibilities of 1 values
predict(model)
#Plot density function approximation
plot(model)
#Prepare data set converting
#all variables to numeric vectors
h <- data.frame("male" = as.numeric(titanic_train$Sex == "male"))
h$class_1 <- as.numeric(titanic_train$Pclass == 1)
h$class_2 <- as.numeric(titanic_train$Pclass == 2)
h$class_3 <- as.numeric(titanic_train$Pclass == 3)
h$sibl <- titanic_train$SibSp
h$survived <- titanic_train$Survived
h$age <- titanic_train$Age
h$parch <- titanic_train$Parch
h$fare <- titanic_train$Fare
#Estimate model parameters
model_hpa_1 <- hpaBinary(survived ~class_1 + class_2 +
male + age + sibl + parch + fare,
K = 3, data = h)
#get summary
summary(model_hpa_1)
help(hpaSelection)
roxygen2::roxygenize(".", roclets="rd")
help(hpaSelection)
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
library("mvtnorm")
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
hpaSelection(selection = z ~ x1 + x2, data = h, z_K = 2, y_K = 2)
hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 2, y_K = 2)
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Sample size
n <- 1000
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 2, y_K = 2)
summary(model)
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1)
summary(model)
system.time(hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1))
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1)
summary(model)
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 2)
summary(model)
system.time(hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 2))
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Sample size
n <- 500
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1)
summary(model)
system.time(hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1))
system.time(hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1))
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Sample size
n <- 500
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1)
summary(model)
#Plot outcome equation random errorrs density
plot(model,TRUE)
#Plot selection equation random errorrs density
plot(model,FALSE)
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Sample size
n <- 500
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 1)
summary(model)
#Plot outcome equation random errorrs density
plot(model,TRUE)
#Plot selection equation random errorrs density
plot(model,FALSE)
hist(epsilon)
#Plot outcome equation random errorrs density
plot(model,TRUE)
#Plot selection equation random errorrs density
plot(model,FALSE)
#Predict conditional y|z=i (i={1,0})
model_pred <- predict(model,is_cond = TRUE)
model_pred
model_pred$y
#Conditional predictions y|z=1
model_pred$y_1
#Unconditional predictions
model_pred$y
#Conditional predictions y|z=1
model_pred$y_1
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 1, y_K = 2)
summary(model)
#Unconditional predictions
model_pred$y
#Get predictions for selection equation
model_pred <- predict(model,is_cond = TRUE)
#Unconditional predictions
model_pred$y
#Conditional predictions y|z=1
model_pred$y_1
#Conditional predictions y|z=0
model_pred$y_0
#Unconditional predictions
model_pred$y
#Conditional predictions y|z=1
model_pred$y_1
#Conditional predictions y|z=0
model_pred$y_0
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 2, y_K = 2)
#Get predictions for selection equation
model_pred <- predict(model,is_cond = TRUE)
#Unconditional predictions
model_pred$y
#Conditional predictions y|z=1
model_pred$y_1
#Conditional predictions y|z=0
model_pred$y_0
#Conditional predictions y|z=1
model_pred$y_1
#Unconditional predictions
model_pred$y
#Conditional predictions y|z=1
model_pred$y_1
#Get unconditional predictions for selection equation
model_pred_u <- predict(model,is_cond = FALSE)
#Get unconditional predictions for selection equation
model_pred_u <- predict(model,is_cond = FALSE)
model_pred_u$y
#Get unconditional predictions for selection equation
model_pred_u <- predict(model,is_cond = FALSE)
model_pred_u$y
#Get unconditional predictions for selection equation
model_pred_u <- predict(model,is_cond = FALSE)
model_pred_u$y
#Get unconditional predictions for selection equation
model_pred_u <- predict(model,is_cond = FALSE)
model_pred_u$y
model_pred_sel_c <- predict(model,is_cond = TRUE, is_outcome = FALSE)
model_pred_sel_c
#Get unconditional predictions for selection equation
model_pred_sel_u <- predict(model,is_cond = FALSE, is_outcome = FALSE)
#Get conditional predictions for selection equation
#Note that for z=0 these predictions are NA
predict(model,is_cond = TRUE, is_outcome = FALSE)
#Get unconditional predictions for selection equation
predict(model,is_cond = FALSE, is_outcome = FALSE)
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Sample size
n <- 500
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 2, y_K = 2)
summary(model)
#Get conditional predictions for outcome equation
model_pred_c <- predict(model,is_cond = TRUE)
#Conditional predictions y|z=1
model_pred_c$y_1
#Conditional predictions y|z=0
model_pred_c$y_0
#Get unconditional predictions for outcome equation
model_pred_u <- predict(model,is_cond = FALSE)
model_pred_u$y
#Get conditional predictions for selection equation
#Note that for z=0 these predictions are NA
predict(model,is_cond = TRUE, is_outcome = FALSE)
#Get unconditional predictions for selection equation
predict(model,is_cond = FALSE, is_outcome = FALSE)
library("hpa")
roxygen2::roxygenize(".", roclets="rd")
help(hpaSelection)
# Not run:
##Let's estimate wage equation accounting for non-random selection.
##See the reference to Mroz TA (1987) to get additional details about
##the data this examples use
#Prepare data
library("sampleSelection")
data("Mroz87")
h = data.frame("kids" = as.numeric(Mroz87$kids5 + Mroz87$kids618 > 0),
"age" = as.numeric(Mroz87$age),
"faminc" = as.numeric(Mroz87$faminc),
"educ" = as.numeric(Mroz87$educ),
"exper" = as.numeric(Mroz87$exper),
"city" = as.numeric(Mroz87$city),
"wage" = as.numeric(Mroz87$wage),
"lfp" = as.numeric(Mroz87$lfp))
#Estimate model parameters
model <- hpaSelection(selection = lfp ~ age + I(age^2) + I(log(faminc)) + educ + kids,
outcome = log(wage) ~exper + I(exper ^ 2) + educ + city,
z_K = 1, y_K = 1, data = h)
summary(model)
# Not run:
##Let's estimate wage equation accounting for non-random selection.
##See the reference to Mroz TA (1987) to get additional details about
##the data this examples use
#Prepare data
library("sampleSelection")
data("Mroz87")
h = data.frame("kids" = as.numeric(Mroz87$kids5 + Mroz87$kids618 > 0),
"age" = as.numeric(Mroz87$age),
"faminc" = as.numeric(Mroz87$faminc),
"educ" = as.numeric(Mroz87$educ),
"exper" = as.numeric(Mroz87$exper),
"city" = as.numeric(Mroz87$city),
"wage" = as.numeric(Mroz87$wage),
"lfp" = as.numeric(Mroz87$lfp))
#Estimate model parameters
model <- hpaSelection(selection = lfp ~ age + I(age^2) + I(log(faminc)) + educ + kids,
outcome = log(wage) ~exper + I(exper ^ 2) + educ + city,
z_K = 1, y_K = 2, data = h)
summary(model)
#Plot outcome equation random errorrs density
plot(model,TRUE)
#Plot selection equation random errorrs density
plot(model,FALSE)
## End(Not run)
##Estimate semi-nonparametric sample selection model
##parameters on simulated data given chi-squared random errors
set.seed(123)
library("mvtnorm")
#Sample size
n <- 500
#Simulate independent variables
X_rho <- 0.5
X_sigma <- matrix(c(1,X_rho,X_rho,X_rho,1,X_rho,X_rho,X_rho,1), ncol=3)
X <- rmvnorm(n=n, mean = c(0,0,0),
sigma = X_sigma)
#Simulate random errors
epsilon <- matrix(0, n, 2)
epsilon_z_y <- rchisq(n, 5)
epsilon[, 1] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
epsilon[, 2] <- (rchisq(n, 5) + epsilon_z_y) * (sqrt(3/20)) - 3.8736
#Simulate selection equation
z_star <- 1 + 1 * X[,1] + 1 * X[,2] + epsilon[,1]
z <- as.numeric((z_star > 0))
#Simulate outcome equation
y_star <- 1 + 1 * X[,1] + 1 * X[,3] + epsilon[,2]
z <- as.numeric((z_star > 0))
y <- y_star
y[z==0] <- NA
h <- as.data.frame(cbind(z, y, X))
names(h) <- c("z", "y", "x1", "x2", "x3")
#Estimate parameters
model <- hpaSelection(selection = z ~ x1 + x2,
outcome = y ~ x1 + x3,
data = h, z_K = 2, y_K = 2)
summary(model)
#Get conditional predictions for outcome equation
model_pred_c <- predict(model,is_cond = TRUE)
#Conditional predictions y|z=1
model_pred_c$y_1
#Conditional predictions y|z=0
model_pred_c$y_0
#Get unconditional predictions for outcome equation
model_pred_u <- predict(model,is_cond = FALSE)
model_pred_u$y
#Get conditional predictions for selection equation
#Note that for z=0 these predictions are NA
predict(model,is_cond = TRUE, is_outcome = FALSE)
#Get unconditional predictions for selection equation
predict(model,is_cond = FALSE, is_outcome = FALSE)
help(predict.hpaSelection)
help(hpa)
